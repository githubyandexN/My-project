**Обучение модели классификации комментариев**

**Задача:** Определение токсичности комментарии.

**Ключевые навыки:** обработка естественного языка, NLP

**Описание:** Интернет-магазин запускает новый сервис. 

Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. 

То есть клиенты предлагают свои правки и комментируют изменения других.

Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

---

*Итоги исследования*

Для построения модели и достижения целевого значения метрики выполнены следующие шаги:

1) Проведено исследование данных: Дубликаты отсутствуют. В датасете ярко выражен дисбаланс классов (разница в 7 раз: 20 тыс токсичных против 140 тыс положительных). Удален дублирующий индексы столбец.

2) Произведена лемматизация текста и очистка данных, составлена визуализация самых повторяемых токсичных слов и положительных комментариев

3) Применен метод upsampling для устранения дисбаланса классов целевого показателя.

4) Выполнен подбор метода векторизации. По итогам выбора метода векторизации и применения модели Логистической регрессии с расчетом метрики F1, лучший результат показал метод метод "Мешок слов", метрика F1 = 0,75

Но модели было мало такое количество итераций, и увеличение их потребляет много ресурсов по времени.

На втором месте по результатам метод "TF-IDF". Этот метод показал результат на втором месте F1 = 0,70, при обучении модели никаких сложностей не возникло, поэтому дальнейшее обучение моделей с подбором гиперпараметров будет с этой векторизацией.

На третьем месте стал "N-грамм" с метрикой F1 = 0,56. Недостатком этого метода является создание достаточно большого размера матрицы, что может увеличить в последствии время обучения модели.

5) Для решения задачи использовали 4 модели: DecisionTreeClassifier, LGBMClassifier, LogisticRegression, CatBoostClassifier.

Лучшая модель с гиперпараметрами оказалась: Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()), ('randomoversampler', RandomOverSampler(random_state=55, sampling_strategy='minority')), ('decisiontreeclassifier', LogisticRegression(C=2, penalty='l1', random_state=55, solver='liblinear'))]) Метрика лучшей модели на кросс-валидации: 0.7702086096354576

6) Метрика лучшей модели на тестовой выборке оказалась F1 = 0.775. Целевое значение достигнуто.
